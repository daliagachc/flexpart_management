{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flexpart_management.modules.flx_array as fa\n",
    "\n",
    "from useful_scit.imps import *\n",
    "import flexpart_management.modules.constants as co\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn\n",
    "# from main import dfcc\n",
    "from flexpart_management.modules.flx_array import weighted_quantile\n",
    "\n",
    "\n",
    "def plot_general(ds1):\n",
    "    cl = co.CPer\n",
    "    c1 = ds1[cl].sum([co.RL, co.ZM])\n",
    "    c2 = ds1[cl].sum([co.ZM, co.RL, co.TH_CENTER])\n",
    "    ar = c1 / c2\n",
    "    # ar = c1\n",
    "    ar = ar.isel(**{co.R_CENTER: slice(0, -3)})\n",
    "    ax = fa.get_ax_bolivia(fig_args={'figsize': (5, 5)})\n",
    "    fa.logpolar_plot(ar, name=co.CPer, ax=ax, perM=.95, perm=.01)\n",
    "    ax.set_xlim(-75, -60)\n",
    "    ax.set_ylim(-25, -7)\n",
    "    return ax\n",
    "\n",
    "def plot_general_lapaz(ds1):\n",
    "    cl = co.CPer\n",
    "    c1 = ds1[cl].sum([co.RL, co.ZM])\n",
    "    c2 = ds1[cl].sum([co.ZM, co.RL, co.TH_CENTER])\n",
    "    ar = c1 / c2\n",
    "    # ar = c1\n",
    "    ar = ar.isel(**{co.R_CENTER: slice(0, -3)})\n",
    "    ax = fa.get_ax_lapaz(fig_args={'figsize': (5, 5)})\n",
    "    fa.logpolar_plot(ar, name=co.CPer, ax=ax, perM=.95, perm=.01)\n",
    "    # ax.set_xlim(-75, -60)\n",
    "    # ax.set_ylim(-25, -7)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_hist_log(dfcc, cumulative=False, ax=False, nbins=20):\n",
    "    _fl = dfcc.sum(axis=1).values\n",
    "    bins = np.logspace(\n",
    "        np.log10(_fl.max() * 1e-5),\n",
    "        np.log10(_fl.max()),\n",
    "        nbins\n",
    "    )\n",
    "    bins = [-bins[0], 0, *bins]\n",
    "    if ax is False:\n",
    "        f, ax = plt.subplots()\n",
    "    else:\n",
    "        ax = ax\n",
    "        f = ax.figure\n",
    "    ax.hist(\n",
    "        _fl,\n",
    "        bins=bins,\n",
    "        weights=[100 / len(_fl)] * len(_fl),\n",
    "        cumulative=cumulative,\n",
    "        alpha=.5\n",
    "    )\n",
    "    ax: plt.Axes\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim((bins[2] * .5, bins[-1]))\n",
    "    ax.set_xlabel('mass*res.time ')\n",
    "    ax.set_ylabel('%')\n",
    "    cell_tile = \"Sum Values over cell\"\n",
    "    if cumulative is True:\n",
    "        cell_tile = cell_tile + ' (cumulative)'\n",
    "    ax.set_title(cell_tile)\n",
    "\n",
    "\n",
    "def plot_hist_all_log(dfcc, cumulative=False, ax=False):\n",
    "    _fl = dfcc.values.flatten()\n",
    "\n",
    "    bins = np.logspace(\n",
    "        np.log10(dfcc.max().max() * 1e-5),\n",
    "        np.log10(dfcc.max().max()),\n",
    "        10\n",
    "    )\n",
    "    bins = [-bins[0], 0, *bins]\n",
    "    if ax is False:\n",
    "        f, ax = plt.subplots()\n",
    "    else:\n",
    "        ax = ax\n",
    "        f = ax.figure\n",
    "    ax.hist(\n",
    "        _fl,\n",
    "        bins=bins,\n",
    "        weights=[100 / len(_fl)] * len(_fl),\n",
    "        cumulative=cumulative,\n",
    "        alpha=.5\n",
    "    )\n",
    "    ax.set_xscale('log')\n",
    "    ax: plt.Axes\n",
    "    # ax.set_xscale('symlog')\n",
    "    ax.set_xlim((bins[2] * .5, bins[-1]))\n",
    "    ax.set_xlabel('mass*res.time ')\n",
    "    ax.set_ylabel('%')\n",
    "    cell_tile = \"All Values over cell\"\n",
    "    if cumulative is True:\n",
    "        cell_tile = cell_tile + ' (cumulative)'\n",
    "    ax.set_title(cell_tile)\n",
    "\n",
    "\n",
    "def plot_silhouette_score(\n",
    "        n_c,\n",
    "        sample_silhouette_values,\n",
    "        cluster_labels,\n",
    "        ax1,\n",
    "        silhouette_avg\n",
    "):\n",
    "    y_lower = 10\n",
    "    for i in range(n_c):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = [*ucp.cc, *ucp.cc][i]\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "    # ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_title(str(n_c))\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    # ax1.axvline(x=sil_avg, color=\"red\", linestyle=\"-\")\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    # ax1.set_xticks([-0.1, 0, 0.2, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ax = fa.get_ax_lapaz()\n",
    "# fa.logpolar_plot(ar,name=co.CPer,ax=ax,perM=.95)\n",
    "\n",
    "\n",
    "def plot_hist_values(dfcc):\n",
    "    # global f, axs\n",
    "    f, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs = axs.flatten()\n",
    "    plot_hist_log(dfcc, ax=axs[0])\n",
    "    plot_hist_log(dfcc, cumulative=True, ax=axs[1])\n",
    "    f: plt.Figure\n",
    "    f.tight_layout()\n",
    "\n",
    "\n",
    "def plot_sil_score_grid(dscc):\n",
    "    fig = plt.figure(figsize=(20, 40))\n",
    "    for i in range(len(dscc[co.CLUS_LENGTH_DIM])):\n",
    "        ii = dscc[co.CLUS_LENGTH_DIM][i].item()\n",
    "        _d = dscc.loc[{co.CLUS_LENGTH_DIM: ii}][\n",
    "            [co.FLAG, co.SIL_SC, co.SIL_SAMPLE]].stack(\n",
    "            {co.DUM_STACK: [co.R_CENTER, co.TH_CENTER, co.ZM]})\n",
    "        if i == 0:\n",
    "            ax0 = ax = fig.add_subplot(5, 5, i + 1)\n",
    "        else:\n",
    "            ax = fig.add_subplot(5, 5, i + 1, sharex=ax0)\n",
    "\n",
    "        plot_silhouette_score(\n",
    "            n_c=ii,\n",
    "            silhouette_avg=_d[co.SIL_SC],\n",
    "            sample_silhouette_values=_d[co.SIL_SAMPLE].values,\n",
    "            cluster_labels=_d[co.FLAG].values,\n",
    "            ax1=ax\n",
    "        )\n",
    "\n",
    "def calc_silhouette_scores(dscc):\n",
    "    _fl = dscc.where(dscc[co.LAB_CLUSTER_THRESHOLD])[\n",
    "        [co.FLAG, co.CONC_NORMALIZED]].stack(\n",
    "        {co.DUM_STACK: [co.R_CENTER, co.TH_CENTER, co.ZM]})\n",
    "    # %%\n",
    "    _fl = _fl.dropna(co.DUM_STACK)\n",
    "    # %%\n",
    "    _cl = _fl[co.CLUS_LENGTH_DIM]\n",
    "    # %%\n",
    "    _sil_sc = xr.full_like(dscc[co.CLUS_LENGTH_DIM], np.nan, float)\n",
    "    _sil_sc.name = co.SIL_SC\n",
    "    for i, _ in _cl.to_series().iteritems():\n",
    "        #     print(i)\n",
    "        _labs = _fl.sel(**{co.CLUS_LENGTH_DIM: i})[co.FLAG]\n",
    "        _CC = _fl.sel(**{co.CLUS_LENGTH_DIM: [i]})[co.CONC_NORMALIZED]\n",
    "        _scc = sklearn.metrics.silhouette_score(_CC.T, _labs)\n",
    "        _sil_sc.loc[{co.CLUS_LENGTH_DIM: i}] = _scc\n",
    "    # %%\n",
    "    try:\n",
    "        dscc = dscc.drop(co.SIL_SC)\n",
    "    except:\n",
    "        pass\n",
    "    dscc = xr.merge([dscc, _sil_sc])\n",
    "    # %%\n",
    "    # %%\n",
    "    _sil_sa = xr.full_like(_fl[co.FLAG], np.nan, float)\n",
    "    _sil_sa.name = co.SIL_SAMPLE\n",
    "    for i, _ in _cl.to_series().iteritems():\n",
    "        print(i)\n",
    "        _labs = _fl.sel(**{co.CLUS_LENGTH_DIM: i})[co.FLAG]\n",
    "        _CC = _fl.sel(**{co.CLUS_LENGTH_DIM: [i]})[co.CONC_NORMALIZED]\n",
    "        _scc = sklearn.metrics.silhouette_samples(_CC.T, _labs)\n",
    "        _sil_sa.loc[{co.CLUS_LENGTH_DIM: i}] = _scc\n",
    "    # %%\n",
    "    try:\n",
    "        dscc = dscc.drop(co.SIL_SAMPLE)\n",
    "    except:\n",
    "        pass\n",
    "    dscc = xr.merge([dscc, _sil_sa.unstack()])\n",
    "    return dscc\n",
    "\n",
    "def plot_bar_charts_for_each_cluster_set(dscc):\n",
    "    _ser = dscc[co.FLAG].to_series()\n",
    "    _ser = _ser.groupby(co.CLUS_LENGTH_DIM).value_counts().sort_index()\n",
    "    # %%\n",
    "    _s1 = _ser.unstack(co.FLAG).T\n",
    "    # %%\n",
    "    _s1.plot.bar(subplots=True, layout=(-1, 4), figsize=(20, 10),\n",
    "                 legend=False);\n",
    "\n",
    "def do_clust_multiple(dscc):\n",
    "    _co = co.CONC_NORMALIZED\n",
    "    _ser = dscc[_co].where(dscc[co.LAB_CLUSTER_THRESHOLD]).to_dataframe()[\n",
    "        _co].dropna()\n",
    "    _ser = _ser.unstack(co.RL)\n",
    "    # %%\n",
    "    _co = co.CONC_NORMS\n",
    "    _wei = dscc[_co].where(dscc[co.LAB_CLUSTER_THRESHOLD]).to_dataframe()[\n",
    "        _co].dropna()\n",
    "    _wei = _wei / _wei.median()\n",
    "\n",
    "    # _wei = _wei.unstack(co.RL)\n",
    "    # %%\n",
    "    # %%\n",
    "    def set_kmeans(n_c, _ser, _wei):\n",
    "        #     n_c = 30\n",
    "        kmeans = KMeans(n_c, random_state=388345)\n",
    "        kmeans.fit(_ser, _wei)\n",
    "        return kmeans\n",
    "\n",
    "    # %%\n",
    "    _dc = dscc[co.CLUS_LENGTH_DIM].to_dataframe()\n",
    "    _dc[co.KMEAN_OBJ] = _dc.apply(\n",
    "        lambda r: set_kmeans(r[co.CLUS_LENGTH_DIM], _ser, _wei), axis=1)\n",
    "    _dc.drop(co.CLUS_LENGTH_DIM, axis=1, inplace=True)\n",
    "    # %%\n",
    "    dscc[co.KMEAN_OBJ] = _dc.to_xarray()[co.KMEAN_OBJ]\n",
    "    # %%\n",
    "    _kmeans = dscc[co.KMEAN_OBJ].to_series()\n",
    "    # %%\n",
    "    _dm = dscc[co.CONC_NORMALIZED].stack(\n",
    "        {co.DUM_STACK: [co.R_CENTER, co.TH_CENTER, co.ZM]}).T\n",
    "    # _dm = _dm.isel(dum=slice(None,4))\n",
    "    _nas = []\n",
    "    for i, ob in _kmeans.items():\n",
    "        _na = xr.full_like(_dm, np.nan).sum(co.RL)\n",
    "        _na.name = co.FLAG\n",
    "        _na.values = ob.predict(_dm)\n",
    "        _na = _na.expand_dims(**{co.CLUS_LENGTH_DIM: [i]}).unstack()\n",
    "        _nas.append(_na)\n",
    "    # %%\n",
    "    _na = xr.concat(_nas, dim=co.CLUS_LENGTH_DIM)\n",
    "    # %%\n",
    "    try:\n",
    "        dscc = dscc.drop(co.FLAG)\n",
    "    except:\n",
    "        pass\n",
    "    dscc = xr.merge([dscc, _na])\n",
    "    return dscc\n",
    "\n",
    "def plot_sample_of_vectors_norm_used_for_clustering(dscc):\n",
    "    global _df\n",
    "    _col = co.CONC_NORMALIZED\n",
    "    _df = dscc.where(dscc[co.LAB_CLUSTER_THRESHOLD])[_col].to_dataframe()[\n",
    "        _col].dropna()\n",
    "    _df = _df.unstack(co.RL)\n",
    "    # %%\n",
    "    _sam = _df.sample(frac=.001).T.plot(legend=False, alpha=.7,\n",
    "                                        figsize=(10, 5))\n",
    "\n",
    "def plot_cells_used_for_clustering(dscc):\n",
    "    _ds = dscc[co.LAB_CLUSTER_THRESHOLD].to_dataframe()[\n",
    "        co.LAB_CLUSTER_THRESHOLD].value_counts()\n",
    "    _ds = 100 * _ds / _ds.sum()\n",
    "    ax = _ds.plot.bar()\n",
    "    ax.set_title('cells used for clustering');\n",
    "\n",
    "def preprocess_dscc_for_clustering(MAX_LENGTH, dscc):\n",
    "    co.CLUS_LENGTH_DIM\n",
    "    dscc = dscc.assign_coords(**{co.CLUS_LENGTH_DIM: range(2, MAX_LENGTH)})\n",
    "    # %%\n",
    "    stack_dic = {co.DUM_STACK: [co.R_CENTER, co.TH_CENTER, co.ZM]}\n",
    "    _norm = dscc[co.CONC].stack(**stack_dic)\n",
    "    _norm_array, _norm_ret = preprocessing.normalize(_norm,\n",
    "                                                     return_norm=True,\n",
    "                                                     axis=0)\n",
    "    _norm.values = _norm_array\n",
    "    dscc[co.CONC_NORMALIZED] = _norm.unstack()\n",
    "    _normed = _norm.mean(co.RL)\n",
    "    _normed.name = co.CONC_NORMS\n",
    "    _normed.values = _norm_ret\n",
    "    _normed = _normed.unstack()\n",
    "    dscc[co.CONC_NORMS] = _normed\n",
    "    # dscc[co.CONC_NORMS] = dscc[co.CONC_NORMS].where(dscc[co.LAB_CLUSTER_THRESHOLD])\n",
    "    # %%\n",
    "    try:\n",
    "        dscc = dscc.drop('quantile')\n",
    "    except:\n",
    "        pass\n",
    "    return dscc\n",
    "\n",
    "def print_percentage_res_time_mass_considered(dscc):\n",
    "    # %%\n",
    "    _res = (dscc[co.CONC].where(dscc[co.LAB_CLUSTER_THRESHOLD])).sum() / \\\n",
    "           dscc[co.CONC].sum()\n",
    "    # %%\n",
    "    print((100 * _res).item())\n",
    "\n",
    "def rebuild_the_dscc(dfcc):\n",
    "    global _df\n",
    "    _df = dfcc\n",
    "    dscc = _df[co.CONC].stack().to_xarray()\n",
    "    dscc.name = co.CONC\n",
    "    dscc = dscc.to_dataset()\n",
    "    CLUSTER_THRESHOLD = .4\n",
    "    co.LAB_CLUSTER_THRESHOLD = 'LAB_CLUSTER_THRESHOLD'\n",
    "    co.CSUM = 'CONC_SUM'\n",
    "    # %%\n",
    "    dscc[co.CSUM] = dscc[co.CONC].sum(co.RL)\n",
    "    # %%\n",
    "    dscc[co.LAB_CLUSTER_THRESHOLD] = dscc[co.CSUM] > dscc[co.CSUM].quantile(\n",
    "        CLUSTER_THRESHOLD)\n",
    "    return dscc\n",
    "\n",
    "def plot_hist_all_values(dfcc):\n",
    "    f, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs = axs.flatten()\n",
    "    plot_hist_all_log(dfcc, ax=axs[0])\n",
    "    plot_hist_all_log(dfcc, cumulative=True, ax=axs[1])\n",
    "    f: plt.Figure\n",
    "    f.tight_layout()\n",
    "\n",
    "def get_df_for_plot(_n, dscc):\n",
    "    _d = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "    _d = _d.drop([co.KMEAN_OBJ, co.CLUS_LENGTH_DIM])\n",
    "    # _d = _d.where(_d[FLAG]==_f)\n",
    "    # %%\n",
    "    _s = _d[[co.CONC, co.FLAG]].to_dataframe()[[co.CONC, co.FLAG]]\n",
    "    _ss = _s.groupby([co.RL, co.FLAG]).sum()\n",
    "    # %%\n",
    "    _ss1 = _ss.unstack(co.FLAG).resample('4H').mean()\n",
    "    _ss1 = (100 * _ss1[co.CONC].T / _ss1.T.sum()).T\n",
    "    # %%\n",
    "    _ss1.plot(sharex=True, sharey=True, layout=(2, -1), subplots=True,\n",
    "              figsize=(10, 5), color=ucp.cc);\n",
    "    # %%\n",
    "    _ss1.plot.area(legend=False, figsize=(12, 6), color=ucp.cc)\n",
    "    # %%\n",
    "    # %%\n",
    "    _ss1 = _ss.unstack(co.FLAG)\n",
    "    # %%\n",
    "    _ss1 = _ss1.resample('m').median()\n",
    "    # %%\n",
    "    _ss1 = (100 * _ss1[co.CONC].T / _ss1.T.sum()).T\n",
    "    return _ss1\n",
    "\n",
    "\n",
    "def add_lat_lon_to_dscc(dscc, selfFLP):\n",
    "    lcols = [*co.LL00, 'LON', 'LAT']\n",
    "    _ds = selfFLP.merged_ds\n",
    "    _ds = _ds[lcols]\n",
    "    dscc = dscc.drop(lcols)\n",
    "    try:\n",
    "        dscc = xr.merge([dscc, _ds])\n",
    "    except:\n",
    "        pass\n",
    "    # dscc = xr.merge([dscc,_ds])\n",
    "    return dscc\n",
    "\n",
    "\n",
    "def plot_hour_influence_targeted(_n, _nn, dscc, height_less_than,\n",
    "                                 less_than, more_than):\n",
    "    _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "    try: _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "    except: pass\n",
    "    _dss = _ds.copy()\n",
    "    _ds[co.CONC] = _ds[co.CONC].where(dscc[co.R_CENTER] < less_than,\n",
    "                                      0).where(\n",
    "        dscc[co.R_CENTER] > more_than, 0).where(\n",
    "        dscc[co.ZM] < height_less_than, 0)\n",
    "    _ds1 = _ds[[co.CONC, co.FLAG]]\n",
    "    _dss1 = _dss[[co.CONC, co.FLAG]]\n",
    "    _ds2 = _ds1.to_dataframe()\n",
    "    _dss2 = _dss1.to_dataframe()\n",
    "    _ds3 = _ds2[[co.CONC, co.FLAG]]\n",
    "    _dss3 = _dss2[[co.CONC, co.FLAG]]\n",
    "    _df = _ds3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                           drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _dff = _dss3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                             drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _df1 = _df.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _dff1 = _dff.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _df2 = _df1.unstack(co.FLAG)[co.CONC]\n",
    "    _dff2 = _dff1.unstack(co.FLAG)[co.CONC]\n",
    "    _df2 = 100 * (_df2.T / _dff2.T.sum()).T\n",
    "    # %%\n",
    "    _df3 = _df2.loc[:, _nn].copy()\n",
    "    _df3.index = (_df3.index - pd.Timedelta(hours=4)).hour\n",
    "    ax = _df3.sort_index().reset_index().boxplot(by=co.RL)\n",
    "    ax.set_ylim(-.01, .5);\n",
    "    # ax.set_yscale('log')\n",
    "    # ax.set_title('')\n",
    "\n",
    "def plot_target_distance_height_influence(_n, dscc, height_less_than,\n",
    "                                          less_than, more_than):\n",
    "    _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "    try: _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "    except: pass\n",
    "\n",
    "    _dss = _ds.copy()\n",
    "    _ds[co.CONC] = _ds[co.CONC].where(dscc[co.R_CENTER] < less_than,\n",
    "                                      0).where(\n",
    "        dscc[co.R_CENTER] > more_than, 0).where(\n",
    "        dscc[co.ZM] < height_less_than, 0)\n",
    "    _ds1 = _ds[[co.CONC, co.FLAG]]\n",
    "    _dss1 = _dss[[co.CONC, co.FLAG]]\n",
    "    _ds2 = _ds1.to_dataframe()\n",
    "    _dss2 = _dss1.to_dataframe()\n",
    "    _ds3 = _ds2[[co.CONC, co.FLAG]]\n",
    "    _dss3 = _dss2[[co.CONC, co.FLAG]]\n",
    "    _df = _ds3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                           drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _dff = _dss3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                             drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _df1 = _df.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _dff1 = _dff.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _df2 = _df1.unstack(co.FLAG)[co.CONC]\n",
    "    _dff2 = _dff1.unstack(co.FLAG)[co.CONC]\n",
    "    _df2 = 100 * (_df2.T / _dff2.T.sum()).T\n",
    "    _df2.plot(subplots=True, figsize=(20, 20), sharey=True,\n",
    "              color=[*ucp.cc, *ucp.cc]);\n",
    "\n",
    "def plot_influences(_n, dscc):\n",
    "    _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "    try: _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "    except: pass\n",
    "    _dss = _ds.copy()\n",
    "    _ds[co.CONC] = _ds[co.CONC]\n",
    "    _ds1 = _ds[[co.CONC, co.FLAG]]\n",
    "    _dss1 = _dss[[co.CONC, co.FLAG]]\n",
    "    _ds2 = _ds1.to_dataframe()\n",
    "    _dss2 = _dss1.to_dataframe()\n",
    "    _ds3 = _ds2[[co.CONC, co.FLAG]]\n",
    "    _dss3 = _dss2[[co.CONC, co.FLAG]]\n",
    "    _df = _ds3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                           drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _dff = _dss3.reset_index([co.R_CENTER, co.TH_CENTER, co.ZM],\n",
    "                             drop=True).reset_index().set_index(\n",
    "        [co.FLAG, co.RL])\n",
    "    _df1 = _df.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _dff1 = _dff.sort_index().groupby([co.FLAG, co.RL]).sum()\n",
    "    _df2 = _df1.unstack(co.FLAG)[co.CONC]\n",
    "    _dff2 = _dff1.unstack(co.FLAG)[co.CONC]\n",
    "    _df2 = 100 * (_df2.T / _dff2.T.sum()).T\n",
    "    _df2.plot(subplots=True, figsize=(20, 20), sharey=True,\n",
    "              color=[*ucp.cc, *ucp.cc]);\n",
    "\n",
    "def plot_dis_height_quantiles_chc(_n, dsF, dscc, axs=False):\n",
    "    for _f in range(_n):\n",
    "        _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "\n",
    "        # _ds = dscc.loc[{CLUS_LENGTH_DIM:_n}]\n",
    "        _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "        # _ds = _ds.where(_ds[FLAG]==_f)\n",
    "        _ds = _ds.sum([co.RL])\n",
    "\n",
    "        _ds1 = xr.merge([_ds, dsF[co.TOPO].mean(co.RL)]).where(\n",
    "            _ds[co.FLAG] == _f)\n",
    "        HEIGHT = 'HEIGHT'\n",
    "        _ds1[HEIGHT] = (_ds1[co.TOPO] + _ds1[co.ZM])\n",
    "        _ds1 = _ds1.swap_dims({co.R_CENTER: co.DIS})\n",
    "\n",
    "        _dg = _ds1[[HEIGHT, co.CONC]].to_dataframe()[[HEIGHT, co.CONC]]\n",
    "\n",
    "        _dg = _dg.groupby(co.DIS)\n",
    "\n",
    "        def _fun(df, q=100):\n",
    "            global _df\n",
    "            _df = df\n",
    "            _df = _df.dropna()\n",
    "            if len(_df) == 0:\n",
    "                return np.nan\n",
    "            if _df[co.CONC].max() == 0:\n",
    "                return np.nan\n",
    "            _h = _df[HEIGHT].values\n",
    "            _w = _df[co.CONC].values\n",
    "            ret = weighted_quantile(_h, q, sample_weight=_w)\n",
    "\n",
    "            return ret\n",
    "\n",
    "        if axs is False:\n",
    "            _, ax = plt.subplots()\n",
    "        else:\n",
    "            ax = axs[_f]\n",
    "        _dg1 = _dg.apply(_fun, q=.75)\n",
    "        _dg1.plot(x=co.DIS, ax=ax, color=[[*ucp.cc, *ucp.cc][_f]])\n",
    "        _dg1 = _dg.apply(_fun, q=.25)\n",
    "        _dg1.plot(x=co.DIS, ax=ax, color=[[*ucp.cc, *ucp.cc][_f]])\n",
    "        ax.set_xscale('log')\n",
    "        # ax.set_yscale('log')\n",
    "        ax.set_xlim(10, 2e3)\n",
    "        # ax.set_ylim(25e1,2e4)\n",
    "        ax.set_title(str(_f));\n",
    "\n",
    "        _dh = (_ds1[co.CONC] * (_ds1[co.TOPO] + _ds1[co.ZM])).mean(\n",
    "            [co.TH_CENTER, co.ZM])\n",
    "        _dh = _dh / (_ds1[co.CONC].mean([co.TH_CENTER, co.ZM]))\n",
    "\n",
    "        # _,ax = plt.subplots()\n",
    "        _dh.plot(x=co.DIS, color=[*ucp.cc, *ucp.cc][_f], ax=ax)\n",
    "        ax.set_xscale('log')\n",
    "        # ax.set_yscale('log')\n",
    "        ax.set_xlim(10, 2e3)\n",
    "        # ax.set_ylim(25e1,2e4)\n",
    "        ax.set_title(str(_f));\n",
    "        _dh = (_ds1[co.CONC] * (_ds1[co.TOPO])).mean([co.TH_CENTER, co.ZM])\n",
    "        _dh = _dh / (_ds1[co.CONC].mean([co.TH_CENTER, co.ZM]))\n",
    "\n",
    "        # _,ax = plt.subplots()\n",
    "        _dh.plot(x=co.DIS, color='k', ax=ax)\n",
    "        ax.set_xscale('log')\n",
    "        # ax.set_yscale('log')\n",
    "        ax.set_xlim(5, 2e3)\n",
    "        ax.set_ylim(0, 1.5e4)\n",
    "        ax.set_title(str(_f));\n",
    "\n",
    "def add_dis_km_dscc(dscc):\n",
    "    _km = dscc[co.R_CENTER] * 100\n",
    "    _km.name = co.DIS\n",
    "    dscc = dscc.assign_coords(**{co.DIS: _km})\n",
    "    return dscc\n",
    "\n",
    "def plot_distance_height_chc(_n, dscc):\n",
    "    for _f in range(_n):\n",
    "        # ax = fa.get_ax_bolivia()\n",
    "        #     ax.set_title(str(_f))\n",
    "        _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "        _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "        _ds = _ds.where(_ds[co.FLAG] == _f)\n",
    "        _ds = _ds.sum([co.RL, co.TH_CENTER])\n",
    "\n",
    "        _ds = _ds[[co.CONC]]\n",
    "\n",
    "        _cm = fa.get_custom_cmap([*ucp.cc, *ucp.cc, *ucp.cc][_f][:3])\n",
    "\n",
    "        _km = _ds[co.R_CENTER] * 100\n",
    "\n",
    "        DIS = 'Distance [km]'\n",
    "        _km.name = DIS\n",
    "\n",
    "        _ds = _ds.assign_coords(**{DIS: _km})\n",
    "        _, ax = plt.subplots()\n",
    "        _ds[co.CONC].plot(x=DIS, cmap=_cm, ax=ax)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(10, 2e3)\n",
    "        ax.set_ylim(25e1, 2e4)\n",
    "        ax.set_title(str(_f));\n",
    "\n",
    "def plot_clust_bolivia_individual(_n, dscc):\n",
    "    for _f in range(_n):\n",
    "        ax = fa.get_ax_bolivia()\n",
    "        ax.set_title(str(_f))\n",
    "        _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "        _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "        _ds = _ds.where(_ds[co.FLAG] == _f)\n",
    "        _ds = _ds.sum([co.RL, co.ZM])\n",
    "\n",
    "        _ds = _ds[[co.CONC]]\n",
    "\n",
    "        _cm = fa.get_custom_cmap([*ucp.cc, *ucp.cc, *ucp.cc][_f][:3])\n",
    "\n",
    "        fa.logpolar_plot(_ds, ax=ax, patch_args={'cmap': _cm},\n",
    "                         colorbar=False)\n",
    "\n",
    "def plot_clust_in_lapaz(_n, dscc):\n",
    "    for _f in range(_n):\n",
    "        ax = fa.get_ax_lapaz()\n",
    "        ax.set_title(str(_f))\n",
    "        _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}][\n",
    "            {co.R_CENTER: slice(1, 23)}]\n",
    "        _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "        _ds = _ds.where(_ds[co.FLAG] == _f)\n",
    "        _ds = _ds.sum([co.RL, co.ZM])\n",
    "\n",
    "        _ds = _ds[[co.CONC]]\n",
    "\n",
    "        _cm = fa.get_custom_cmap([*ucp.cc, *ucp.cc, *ucp.cc][_f][:3])\n",
    "\n",
    "        if _ds[co.CONC].max().item() != 0:\n",
    "            fa.logpolar_plot(_ds, ax=ax, patch_args={'cmap': _cm},\n",
    "                             colorbar=False)\n",
    "        fa.add_chc_lpb(ax)\n",
    "\n",
    "def plot_clust_in_bolivia(_n, dscc):\n",
    "    ax = fa.get_ax_bolivia()\n",
    "    _f = 2\n",
    "    for _f in range(_n):\n",
    "        _ds = dscc.loc[{co.CLUS_LENGTH_DIM: _n}]\n",
    "        _ds = _ds.drop(co.KMEAN_OBJ)\n",
    "        _ds = _ds.where(_ds[co.FLAG] == _f)\n",
    "        _ds = _ds.sum([co.RL, co.ZM])\n",
    "\n",
    "        _ds = _ds[[co.CONC]]\n",
    "\n",
    "        _cm = fa.get_custom_cmap(ucp.cc[_f][:3])\n",
    "\n",
    "        fa.logpolar_plot(_ds, ax=ax, patch_args={'cmap': _cm},\n",
    "                         colorbar=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "1.2.3"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
